{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7ba8279",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set display options to show all columns and rows\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "#Linear regression models import\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# to split the data\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7550954e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cement</th>\n",
       "      <th>slag</th>\n",
       "      <th>ash</th>\n",
       "      <th>water</th>\n",
       "      <th>superplastic</th>\n",
       "      <th>coarseagg</th>\n",
       "      <th>fineagg</th>\n",
       "      <th>age</th>\n",
       "      <th>strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>141.3</td>\n",
       "      <td>212.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>203.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>971.8</td>\n",
       "      <td>748.5</td>\n",
       "      <td>28</td>\n",
       "      <td>29.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>168.9</td>\n",
       "      <td>42.2</td>\n",
       "      <td>124.3</td>\n",
       "      <td>158.3</td>\n",
       "      <td>10.8</td>\n",
       "      <td>1080.8</td>\n",
       "      <td>796.2</td>\n",
       "      <td>14</td>\n",
       "      <td>23.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.7</td>\n",
       "      <td>187.4</td>\n",
       "      <td>5.5</td>\n",
       "      <td>956.9</td>\n",
       "      <td>861.2</td>\n",
       "      <td>28</td>\n",
       "      <td>29.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>266.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>28</td>\n",
       "      <td>45.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>154.8</td>\n",
       "      <td>183.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>193.3</td>\n",
       "      <td>9.1</td>\n",
       "      <td>1047.4</td>\n",
       "      <td>696.7</td>\n",
       "      <td>28</td>\n",
       "      <td>18.29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cement   slag    ash  water  superplastic  coarseagg  fineagg  age  \\\n",
       "0   141.3  212.0    0.0  203.5           0.0      971.8    748.5   28   \n",
       "1   168.9   42.2  124.3  158.3          10.8     1080.8    796.2   14   \n",
       "2   250.0    0.0   95.7  187.4           5.5      956.9    861.2   28   \n",
       "3   266.0  114.0    0.0  228.0           0.0      932.0    670.0   28   \n",
       "4   154.8  183.4    0.0  193.3           9.1     1047.4    696.7   28   \n",
       "\n",
       "   strength  \n",
       "0     29.89  \n",
       "1     23.51  \n",
       "2     29.22  \n",
       "3     45.85  \n",
       "4     18.29  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('concrete.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7655b6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "std_scale = StandardScaler()\n",
    "std_scale\n",
    "\n",
    "df[\"cement\"] = std_scale.fit_transform(df[[\"cement\"]])\n",
    "df[\"slag\"] = std_scale.fit_transform(df[[\"slag\"]])\n",
    "df[\"ash\"] = std_scale.fit_transform(df[[\"ash\"]])\n",
    "df[\"water\"] = std_scale.fit_transform(df[[\"water\"]])\n",
    "df[\"superplastic\"] = std_scale.fit_transform(df[[\"superplastic\"]])\n",
    "df[\"coarseagg\"] = std_scale.fit_transform(df[[\"coarseagg\"]])\n",
    "df[\"fineagg\"] = std_scale.fit_transform(df[[\"fineagg\"]])\n",
    "df[\"age\"] = std_scale.fit_transform(df[[\"age\"]])\n",
    "df[\"strength\"] = std_scale.fit_transform(df[[\"strength\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6c20555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "73/73 [==============================] - 1s 2ms/step - loss: 0.9724\n",
      "Epoch 2/10\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.6353\n",
      "Epoch 3/10\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.3511\n",
      "Epoch 4/10\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.3208\n",
      "Epoch 5/10\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.2817\n",
      "Epoch 6/10\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.2446\n",
      "Epoch 7/10\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.2123\n",
      "Epoch 8/10\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.1939\n",
      "Epoch 9/10\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.1859\n",
      "Epoch 10/10\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.1802\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x145c54210>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Assigned X and Y\n",
    "X = df.drop(\"strength\", axis = 1)\n",
    "Y = df[[\"strength\"]]\n",
    "\n",
    "# Split train test data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.3, random_state = 1)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Units is number of neurons\n",
    "# Adding input layer\n",
    "# input_dim is number of independent variables\n",
    "model.add(Dense(units = 20, activation = \"relu\", input_dim = 8, kernel_initializer='uniform'))\n",
    "# Adding hidden layers (Hidden Layers includes input layer but input_dim is passed for input)\n",
    "model.add(Dense(units = 20, activation = \"relu\", kernel_initializer='uniform'))\n",
    "model.add(Dense(units = 20, activation = \"relu\", kernel_initializer='uniform'))\n",
    "model.add(Dense(units = 20, activation = \"relu\", kernel_initializer='uniform'))\n",
    "# Adding output layer\n",
    "# For multi class use softmax for binary use sigmoid\n",
    "model.add(Dense(units = 1))\n",
    "\n",
    "model.compile(optimizer = \"adam\", loss = \"mean_squared_error\")\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size = 10, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ace20de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8290412716322604"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "Y_pred = model.predict(X_test)\n",
    "r2_score(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94db2c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1030, 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebee6e10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cement          float64\n",
       "slag            float64\n",
       "ash             float64\n",
       "water           float64\n",
       "superplastic    float64\n",
       "coarseagg       float64\n",
       "fineagg         float64\n",
       "age               int64\n",
       "strength        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f96be8a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cement          0\n",
       "slag            0\n",
       "ash             0\n",
       "water           0\n",
       "superplastic    0\n",
       "coarseagg       0\n",
       "fineagg         0\n",
       "age             0\n",
       "strength        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd7fc7b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cement          0\n",
       "slag            0\n",
       "ash             0\n",
       "water           0\n",
       "superplastic    0\n",
       "coarseagg       0\n",
       "fineagg         0\n",
       "age             0\n",
       "strength        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d0081c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40ded636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cement</th>\n",
       "      <th>slag</th>\n",
       "      <th>ash</th>\n",
       "      <th>water</th>\n",
       "      <th>superplastic</th>\n",
       "      <th>coarseagg</th>\n",
       "      <th>fineagg</th>\n",
       "      <th>age</th>\n",
       "      <th>strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>238.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1118.0</td>\n",
       "      <td>789.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>17.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>213.8</td>\n",
       "      <td>98.1</td>\n",
       "      <td>24.5</td>\n",
       "      <td>181.7</td>\n",
       "      <td>6.7</td>\n",
       "      <td>1066.0</td>\n",
       "      <td>785.5</td>\n",
       "      <td>56.0</td>\n",
       "      <td>47.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>376.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>214.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1003.5</td>\n",
       "      <td>762.4</td>\n",
       "      <td>56.0</td>\n",
       "      <td>36.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>286.3</td>\n",
       "      <td>200.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>144.7</td>\n",
       "      <td>11.2</td>\n",
       "      <td>1004.6</td>\n",
       "      <td>803.7</td>\n",
       "      <td>91.0</td>\n",
       "      <td>76.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>149.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>935.0</td>\n",
       "      <td>623.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>24.58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     cement   slag    ash  water  superplastic  coarseagg  fineagg   age  \\\n",
       "988   238.0    0.0    0.0  185.0           0.0     1118.0    789.0  28.0   \n",
       "386   213.8   98.1   24.5  181.7           6.7     1066.0    785.5  56.0   \n",
       "777   376.0    0.0    0.0  214.6           0.0     1003.5    762.4  56.0   \n",
       "337   286.3  200.9    0.0  144.7          11.2     1004.6    803.7  91.0   \n",
       "238   149.0  153.0  194.0  192.0           8.0      935.0    623.0  28.0   \n",
       "\n",
       "     strength  \n",
       "988     17.54  \n",
       "386     47.13  \n",
       "777     36.30  \n",
       "337     76.80  \n",
       "238     24.58  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_columns = df.select_dtypes(include='number')\n",
    "\n",
    "def remove_outlier(col):\n",
    "    sorted(col)\n",
    "    Q1,Q3 = col.quantile([0.25,0.75])\n",
    "    IQR = Q3-Q1\n",
    "    lower_range = Q1-1.5*IQR\n",
    "    higher_range = Q3+1.5*IQR\n",
    "    return lower_range, higher_range\n",
    "\n",
    "outliers_columns = numeric_columns\n",
    "\n",
    "cleaned_df = df\n",
    "for outlier_col in outliers_columns:\n",
    "    lower, upper = remove_outlier(df[outlier_col])\n",
    "    cleaned_df[outlier_col] = np.where(cleaned_df[outlier_col]>upper, upper, cleaned_df[outlier_col])\n",
    "    cleaned_df[outlier_col] = np.where(cleaned_df[outlier_col]<lower, lower, cleaned_df[outlier_col])\n",
    "    \n",
    "cleaned_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f81a32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN Model \n",
    "Y = cleaned_df[[\"strength\"]]\n",
    "X = cleaned_df.drop([\"strength\"], axis = 1)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.30, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ec2f11c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " n_neighbors: usual  5\n",
      "Train::  0.7895227158003622\n",
      "Test::  0.7044570736421931\n",
      "\n",
      " n_neighbors: usual  6\n",
      "Train::  0.7676299715891652\n",
      "Test::  0.7016036091533768\n",
      "\n",
      " n_neighbors: usual  7\n",
      "Train::  0.7543294959480524\n",
      "Test::  0.705946667733443\n",
      "\n",
      " n_neighbors: usual  8\n",
      "Train::  0.7443693590796229\n",
      "Test::  0.7009947537224389\n",
      "\n",
      " n_neighbors: usual  9\n",
      "Train::  0.7262315028447269\n",
      "Test::  0.6903974876803508\n",
      "\n",
      " n_neighbors: usual  10\n",
      "Train::  0.7095360143991752\n",
      "Test::  0.6731700424458986\n",
      "\n",
      " n_neighbors: usual  11\n",
      "Train::  0.6968675999255034\n",
      "Test::  0.6644165203069112\n",
      "\n",
      " n_neighbors: usual  12\n",
      "Train::  0.6864764078277574\n",
      "Test::  0.6536088965263288\n",
      "\n",
      " n_neighbors: usual  13\n",
      "Train::  0.6797076881618154\n",
      "Test::  0.6398126497198666\n",
      "\n",
      " n_neighbors: usual  14\n",
      "Train::  0.6717631013918635\n",
      "Test::  0.6285571757713768\n",
      "\n",
      " n_neighbors: usual  15\n",
      "Train::  0.6595442468752452\n",
      "Test::  0.619869410844651\n",
      "\n",
      " n_neighbors: usual  16\n",
      "Train::  0.6509409778821134\n",
      "Test::  0.6093736787478966\n",
      "\n",
      " n_neighbors: usual  17\n",
      "Train::  0.6438835980922738\n",
      "Test::  0.6066233660165664\n",
      "\n",
      " n_neighbors: usual  18\n",
      "Train::  0.63331995421093\n",
      "Test::  0.6014870305920386\n",
      "\n",
      " n_neighbors: usual  19\n",
      "Train::  0.6247152176385481\n",
      "Test::  0.5945112258785101\n",
      "\n",
      " n_neighbors: usual  20\n",
      "Train::  0.6154253403357486\n",
      "Test::  0.5884031448126656\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "for n in [5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]:\n",
    "    model_knn = KNeighborsRegressor(n_neighbors=n)\n",
    "    model_knn.fit(X_train, Y_train)\n",
    "    print(\"\\n n_neighbors: usual \", n)\n",
    "    print(\"Train:: \",  model_knn.score(X_train,Y_train))\n",
    "    print(\"Test:: \", model_knn.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f538558f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " n_neighbors: usual p=1  5\n",
      "Train::  0.7766348073161424\n",
      "Test::  0.6970609601410619\n",
      "\n",
      " n_neighbors: usual p=1  6\n",
      "Train::  0.7746279419171644\n",
      "Test::  0.6981037819080547\n",
      "\n",
      " n_neighbors: usual p=1  7\n",
      "Train::  0.7674182210140682\n",
      "Test::  0.687794575728133\n",
      "\n",
      " n_neighbors: usual p=1  8\n",
      "Train::  0.7574264020099873\n",
      "Test::  0.6842314643659091\n",
      "\n",
      " n_neighbors: usual p=1  9\n",
      "Train::  0.7475247441246728\n",
      "Test::  0.6859961796797565\n",
      "\n",
      " n_neighbors: usual p=1  10\n",
      "Train::  0.7377337211502262\n",
      "Test::  0.6754776670541989\n",
      "\n",
      " n_neighbors: usual p=1  11\n",
      "Train::  0.7258036043747207\n",
      "Test::  0.6693895784198445\n",
      "\n",
      " n_neighbors: usual p=1  12\n",
      "Train::  0.7118886689919988\n",
      "Test::  0.6610987369409523\n",
      "\n",
      " n_neighbors: usual p=1  13\n",
      "Train::  0.6984832115105015\n",
      "Test::  0.6455272141638014\n",
      "\n",
      " n_neighbors: usual p=1  14\n",
      "Train::  0.6880407591123201\n",
      "Test::  0.6425429633240549\n",
      "\n",
      " n_neighbors: usual p=1  15\n",
      "Train::  0.6774666240125027\n",
      "Test::  0.6378863380089933\n",
      "\n",
      " n_neighbors: usual p=1  16\n",
      "Train::  0.6737902266893779\n",
      "Test::  0.6325109823900701\n",
      "\n",
      " n_neighbors: usual p=1  17\n",
      "Train::  0.6642774654380708\n",
      "Test::  0.629672925597259\n",
      "\n",
      " n_neighbors: usual p=1  18\n",
      "Train::  0.6556137790190584\n",
      "Test::  0.6190964419206855\n",
      "\n",
      " n_neighbors: usual p=1  19\n",
      "Train::  0.6470024418027456\n",
      "Test::  0.6111955358041906\n",
      "\n",
      " n_neighbors: usual p=1  20\n",
      "Train::  0.6406868908725534\n",
      "Test::  0.6047400667211318\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "for n in [5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]:\n",
    "    model_knn = KNeighborsRegressor(n_neighbors=n, p=1)\n",
    "    model_knn.fit(X_train, Y_train)\n",
    "    print(\"\\n n_neighbors: usual p=1 \", n)\n",
    "    print(\"Train:: \",  model_knn.score(X_train,Y_train))\n",
    "    print(\"Test:: \", model_knn.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14ba5b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeRegression\n",
      "Test:: 0.7291713850821487\n",
      "Train:: 0.8015312828740121\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "Y=df[\"strength\"]\n",
    "# X=df.drop([\"test\"])\n",
    "X = df.drop([\"strength\"], axis=1)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.30, random_state = 1)\n",
    "\n",
    "# Instantiate the model\n",
    "model_dtr = DecisionTreeRegressor(max_depth=5)\n",
    "model_dtr.fit(X_train, Y_train)\n",
    "# Fit the model with the train data\n",
    "print(\"DecisionTreeRegression\")\n",
    "print(\"Test::\", model_dtr.score(X_test, Y_test))\n",
    "print(\"Train::\", model_dtr.score(X_train, Y_train))\n",
    "\n",
    "# DecisionTreeRegression\n",
    "# Test:: 0.8292300666858522\n",
    "# Train:: 0.9434268066005124\n",
    "\n",
    "# DecisionTreeRegression - No\n",
    "# Test:: 0.8677230116874993\n",
    "# Train:: 0.9946689474106676\n",
    "# df[\"strength\"]\n",
    "# \n",
    "# model_dtr = DecisionTreeClassifier(max_depth=2)\n",
    "# model_dtr.fit(X_train, Y_train)\n",
    "# # Fit the model with the train data\n",
    "# print(\"DecisionTreeClassifier\")\n",
    "# print(\"Test::\", model_dtr.score(X_test, Y_test))\n",
    "# print(\"Train::\", model_dtr.score(X_train, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eab7bdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "\n",
    "train_char_label = df[\"strength\"].unique()\n",
    "# train_char_label\n",
    "Credit_Tree_File = open('concrete','w')\n",
    "dot_data = tree.export_graphviz(model_dtr, out_file=Credit_Tree_File, feature_names = list(X_train), class_names = list(train_char_label))\n",
    "Credit_Tree_File.close()\n",
    "# Check in concrete.text copy http://www.webgraphviz.com/?tab=map in generate graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "651dcc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(25,20))\n",
    "# _ = model_dtr.plot_tree(clf, \n",
    "#                    feature_names=iris.feature_names,  \n",
    "#                    class_names=iris.target_names,\n",
    "#                    filled=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4284565d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_Y = cleaned_df[[\"strength\"]]\n",
    "cleaned_X = cleaned_df.drop([\"strength\"], axis = 1)\n",
    "X_cleaned_train, X_cleaned_test, Y_cleaned_train, Y_cleaned_test = train_test_split(cleaned_X, cleaned_Y, test_size = 0.30, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b612d66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Outlier removed n_neighbors:  5\n",
      "Train::  0.7895227158003622\n",
      "Test::  0.7044570736421931\n",
      "\n",
      " Outlier removed n_neighbors:  6\n",
      "Train::  0.7676299715891652\n",
      "Test::  0.7016036091533768\n",
      "\n",
      " Outlier removed n_neighbors:  7\n",
      "Train::  0.7543294959480524\n",
      "Test::  0.705946667733443\n",
      "\n",
      " Outlier removed n_neighbors:  8\n",
      "Train::  0.7443693590796229\n",
      "Test::  0.7009947537224389\n",
      "\n",
      " Outlier removed n_neighbors:  9\n",
      "Train::  0.7262315028447269\n",
      "Test::  0.6903974876803508\n",
      "\n",
      " Outlier removed n_neighbors:  10\n",
      "Train::  0.7095360143991752\n",
      "Test::  0.6731700424458986\n",
      "\n",
      " Outlier removed n_neighbors:  11\n",
      "Train::  0.6968675999255034\n",
      "Test::  0.6644165203069112\n",
      "\n",
      " Outlier removed n_neighbors:  12\n",
      "Train::  0.6864764078277574\n",
      "Test::  0.6536088965263288\n",
      "\n",
      " Outlier removed n_neighbors:  13\n",
      "Train::  0.6797076881618154\n",
      "Test::  0.6398126497198666\n",
      "\n",
      " Outlier removed n_neighbors:  14\n",
      "Train::  0.6717631013918635\n",
      "Test::  0.6285571757713768\n",
      "\n",
      " Outlier removed n_neighbors:  15\n",
      "Train::  0.6595442468752452\n",
      "Test::  0.619869410844651\n",
      "\n",
      " Outlier removed n_neighbors:  16\n",
      "Train::  0.6509409778821134\n",
      "Test::  0.6093736787478966\n",
      "\n",
      " Outlier removed n_neighbors:  17\n",
      "Train::  0.6438835980922738\n",
      "Test::  0.6066233660165664\n",
      "\n",
      " Outlier removed n_neighbors:  18\n",
      "Train::  0.63331995421093\n",
      "Test::  0.6014870305920386\n",
      "\n",
      " Outlier removed n_neighbors:  19\n",
      "Train::  0.6247152176385481\n",
      "Test::  0.5945112258785101\n",
      "\n",
      " Outlier removed n_neighbors:  20\n",
      "Train::  0.6154253403357486\n",
      "Test::  0.5884031448126656\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "for n in [5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]:\n",
    "    model_knn = KNeighborsRegressor(n_neighbors=n)\n",
    "    model_knn.fit(X_train, Y_train)\n",
    "    print(\"\\n Outlier removed n_neighbors: \", n)\n",
    "    print(\"Train:: \",  model_knn.score(X_train,Y_train))\n",
    "    print(\"Test:: \", model_knn.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94309f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier, criterion: squared_error\n",
      "Test:: 0.6569533046319993\n",
      "Train:: 0.7259007389310271\n",
      "DecisionTreeClassifier, criterion: friedman_mse\n",
      "Test:: 0.6569533046319993\n",
      "Train:: 0.7259007389310271\n",
      "DecisionTreeClassifier, criterion: absolute_error\n",
      "Test:: 0.6569350069162025\n",
      "Train:: 0.7217723108935595\n",
      "DecisionTreeClassifier, criterion: poisson\n",
      "Test:: 0.6289348350788969\n",
      "Train:: 0.7455443612511162\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "criterions = [\"squared_error\", \"friedman_mse\", \"absolute_error\", \"poisson\"]\n",
    "for cr in criterions:\n",
    "    model_dtr = DecisionTreeRegressor(max_depth=4, criterion=cr)\n",
    "    model_dtr.fit(X_train, Y_train)\n",
    "    # Fit the model with the train data\n",
    "    print(\"DecisionTreeClassifier, criterion:\", cr)\n",
    "    print(\"Test::\", model_dtr.score(X_test, Y_test))\n",
    "    print(\"Train::\", model_dtr.score(X_train, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22eeeb95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.321086474291743"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = [25,30,46,45,52,23,43,35,38,46,48,52,44,30]\n",
    "np.std(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2238b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.782030583337487"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# arr.to_list.mean()\n",
    "sunny = [25,30,35,38,48]\n",
    "np.std(sunny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d52e87a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.491060010942235"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overcast = [46,43,52,44]\n",
    "np.std(overcast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "71050567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.870142593360955"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rainy = [45,52,23,30,46]\n",
    "np.std(rainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a0f8884c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Outlier removed n_neighbors: usual  5\n",
      "Train::  0.9946689474106676\n",
      "Test::  0.7775874582234754\n",
      "\n",
      " Outlier removed n_neighbors: usual  6\n",
      "Train::  0.9946689474106676\n",
      "Test::  0.7807767125134069\n",
      "\n",
      " Outlier removed n_neighbors: usual  7\n",
      "Train::  0.9946689474106676\n",
      "Test::  0.7829576591024542\n",
      "\n",
      " Outlier removed n_neighbors: usual  8\n",
      "Train::  0.9946689474106676\n",
      "Test::  0.7821517218739441\n",
      "\n",
      " Outlier removed n_neighbors: usual  9\n",
      "Train::  0.9946689474106676\n",
      "Test::  0.781949339253146\n",
      "\n",
      " Outlier removed n_neighbors: usual  10\n",
      "Train::  0.9946689474106676\n",
      "Test::  0.774573970303706\n",
      "\n",
      " Outlier removed n_neighbors: usual  11\n",
      "Train::  0.9946689474106676\n",
      "Test::  0.7695712659258905\n",
      "\n",
      " Outlier removed n_neighbors: usual  12\n",
      "Train::  0.9946689474106676\n",
      "Test::  0.762745735401654\n",
      "\n",
      " Outlier removed n_neighbors: usual  13\n",
      "Train::  0.9946689474106676\n",
      "Test::  0.7546072870950873\n",
      "\n",
      " Outlier removed n_neighbors: usual  14\n",
      "Train::  0.9946689474106676\n",
      "Test::  0.7492885409547902\n",
      "\n",
      " Outlier removed n_neighbors: usual  15\n",
      "Train::  0.9946689474106676\n",
      "Test::  0.7459648809331769\n",
      "\n",
      " Outlier removed n_neighbors: usual  16\n",
      "Train::  0.9946689474106676\n",
      "Test::  0.7424742771353992\n",
      "\n",
      " Outlier removed n_neighbors: usual  17\n",
      "Train::  0.9946689474106676\n",
      "Test::  0.7402127161083434\n",
      "\n",
      " Outlier removed n_neighbors: usual  18\n",
      "Train::  0.9946689474106676\n",
      "Test::  0.7384718641230666\n",
      "\n",
      " Outlier removed n_neighbors: usual  19\n",
      "Train::  0.9946689474106676\n",
      "Test::  0.736319580862704\n",
      "\n",
      " Outlier removed n_neighbors: usual  20\n",
      "Train::  0.9946689474106676\n",
      "Test::  0.7336094380652256\n"
     ]
    }
   ],
   "source": [
    "for n in [5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]:\n",
    "    model_knn = KNeighborsRegressor(n_neighbors=n, p=2, weights=\"distance\")\n",
    "    model_knn.fit(X_train, Y_train)\n",
    "    print(\"\\n Outlier removed n_neighbors: usual \", n)\n",
    "    print(\"Train:: \",  model_knn.score(X_train,Y_train))\n",
    "    print(\"Test:: \", model_knn.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "052e0c20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cement</th>\n",
       "      <th>slag</th>\n",
       "      <th>ash</th>\n",
       "      <th>water</th>\n",
       "      <th>superplastic</th>\n",
       "      <th>coarseagg</th>\n",
       "      <th>fineagg</th>\n",
       "      <th>age</th>\n",
       "      <th>strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>281.167864</td>\n",
       "      <td>73.891893</td>\n",
       "      <td>54.188350</td>\n",
       "      <td>181.543252</td>\n",
       "      <td>6.159029</td>\n",
       "      <td>972.918932</td>\n",
       "      <td>773.439587</td>\n",
       "      <td>38.070388</td>\n",
       "      <td>35.812670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>104.506364</td>\n",
       "      <td>86.266363</td>\n",
       "      <td>63.997004</td>\n",
       "      <td>21.225052</td>\n",
       "      <td>5.802457</td>\n",
       "      <td>77.753954</td>\n",
       "      <td>79.815303</td>\n",
       "      <td>35.782271</td>\n",
       "      <td>16.691447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>102.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>124.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>594.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>192.375000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>164.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>932.000000</td>\n",
       "      <td>730.950000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>23.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>272.900000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>968.000000</td>\n",
       "      <td>779.500000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>34.445000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>350.000000</td>\n",
       "      <td>142.950000</td>\n",
       "      <td>118.300000</td>\n",
       "      <td>192.000000</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>1029.400000</td>\n",
       "      <td>824.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>46.135000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>540.000000</td>\n",
       "      <td>357.375000</td>\n",
       "      <td>200.100000</td>\n",
       "      <td>232.650000</td>\n",
       "      <td>25.500000</td>\n",
       "      <td>1145.000000</td>\n",
       "      <td>963.575000</td>\n",
       "      <td>129.500000</td>\n",
       "      <td>79.772500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            cement         slag          ash        water  superplastic  \\\n",
       "count  1030.000000  1030.000000  1030.000000  1030.000000   1030.000000   \n",
       "mean    281.167864    73.891893    54.188350   181.543252      6.159029   \n",
       "std     104.506364    86.266363    63.997004    21.225052      5.802457   \n",
       "min     102.000000     0.000000     0.000000   124.250000      0.000000   \n",
       "25%     192.375000     0.000000     0.000000   164.900000      0.000000   \n",
       "50%     272.900000    22.000000     0.000000   185.000000      6.400000   \n",
       "75%     350.000000   142.950000   118.300000   192.000000     10.200000   \n",
       "max     540.000000   357.375000   200.100000   232.650000     25.500000   \n",
       "\n",
       "         coarseagg      fineagg          age     strength  \n",
       "count  1030.000000  1030.000000  1030.000000  1030.000000  \n",
       "mean    972.918932   773.439587    38.070388    35.812670  \n",
       "std      77.753954    79.815303    35.782271    16.691447  \n",
       "min     801.000000   594.000000     1.000000     2.330000  \n",
       "25%     932.000000   730.950000     7.000000    23.710000  \n",
       "50%     968.000000   779.500000    28.000000    34.445000  \n",
       "75%    1029.400000   824.000000    56.000000    46.135000  \n",
       "max    1145.000000   963.575000   129.500000    79.772500  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3af93d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "540.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cement'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "230f2e26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cement', 'slag', 'ash', 'water', 'superplastic', 'coarseagg',\n",
       "       'fineagg', 'age', 'strength'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4bd8c730",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "min_max_scale = MinMaxScaler()\n",
    "\n",
    "\n",
    "std_cleaned_df = cleaned_df\n",
    "\n",
    "std_cleaned_df[\"cement\"] = min_max_scale.fit_transform(std_cleaned_df[[\"cement\"]])\n",
    "\n",
    "std_cleaned_df[\"slag\"] = min_max_scale.fit_transform(std_cleaned_df[[\"slag\"]])\n",
    "\n",
    "std_cleaned_df[\"water\"] = min_max_scale.fit_transform(std_cleaned_df[[\"water\"]])\n",
    "\n",
    "std_cleaned_df[\"ash\"] = min_max_scale.fit_transform(std_cleaned_df[[\"ash\"]])\n",
    "\n",
    "std_cleaned_df[\"superplastic\"] = min_max_scale.fit_transform(std_cleaned_df[[\"superplastic\"]])\n",
    "\n",
    "std_cleaned_df[\"coarseagg\"] = min_max_scale.fit_transform(std_cleaned_df[[\"coarseagg\"]])\n",
    "std_cleaned_df[\"fineagg\"] = min_max_scale.fit_transform(std_cleaned_df[[\"fineagg\"]])\n",
    "std_cleaned_df[\"age\"] = min_max_scale.fit_transform(std_cleaned_df[[\"age\"]])\n",
    "\n",
    "\n",
    "std_cleaned_Y = std_cleaned_df[[\"strength\"]]\n",
    "std_cleaned_X = std_cleaned_df.drop([\"strength\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7ac1e3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_std_cleaned_train, X_std_cleaned_test, Y_std_cleaned_train, Y_std_cleaned_test = train_test_split(std_cleaned_X, std_cleaned_Y, test_size = 0.30, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "442aee86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Std + Outlier removed n_neighbors: usual p = 2 5\n",
      "Train::  0.9946689474106676\n",
      "Test::  0.8229192174687181\n",
      "\n",
      " Std + Outlier removed n_neighbors: usual p = 2 6\n",
      "Train::  0.9946689474106676\n",
      "Test::  0.8196802570864168\n",
      "\n",
      " Std + Outlier removed n_neighbors: usual p = 2 7\n",
      "Train::  0.9946689474106676\n",
      "Test::  0.8171742993961997\n",
      "\n",
      " Std + Outlier removed n_neighbors: usual p = 2 8\n",
      "Train::  0.9946689474106676\n",
      "Test::  0.8118692665260401\n",
      "\n",
      " Std + Outlier removed n_neighbors: usual p = 2 9\n",
      "Train::  0.9946689474106676\n",
      "Test::  0.800229095059186\n",
      "\n",
      " Std + Outlier removed n_neighbors: usual p = 2 10\n",
      "Train::  0.9946689474106676\n",
      "Test::  0.7989277223630249\n",
      "\n",
      " Std + Outlier removed n_neighbors: usual p = 2 11\n",
      "Train::  0.9946689474106676\n",
      "Test::  0.7980639598138253\n",
      "\n",
      " Std + Outlier removed n_neighbors: usual p = 2 12\n",
      "Train::  0.9946689474106676\n",
      "Test::  0.7887860822275625\n",
      "\n",
      " Std + Outlier removed n_neighbors: usual p = 2 13\n",
      "Train::  0.9946689474106676\n",
      "Test::  0.7807092356542273\n",
      "\n",
      " Std + Outlier removed n_neighbors: usual p = 2 14\n",
      "Train::  0.9946689474106676\n",
      "Test::  0.7770923951216815\n",
      "\n",
      " Std + Outlier removed n_neighbors: usual p = 2 15\n",
      "Train::  0.9946689474106676\n",
      "Test::  0.7749496555271439\n",
      "\n",
      " Std + Outlier removed n_neighbors: usual p = 2 16\n",
      "Train::  0.9946689474106676\n",
      "Test::  0.7747594792437843\n",
      "\n",
      " Std + Outlier removed n_neighbors: usual p = 2 17\n",
      "Train::  0.9946689474106676\n",
      "Test::  0.7736005391876846\n",
      "\n",
      " Std + Outlier removed n_neighbors: usual p = 2 18\n",
      "Train::  0.9946689474106676\n",
      "Test::  0.7740429997550194\n",
      "\n",
      " Std + Outlier removed n_neighbors: usual p = 2 19\n",
      "Train::  0.9946689474106676\n",
      "Test::  0.7738543208761728\n",
      "\n",
      " Std + Outlier removed n_neighbors: usual p = 2 20\n",
      "Train::  0.9946689474106676\n",
      "Test::  0.7709152448596872\n"
     ]
    }
   ],
   "source": [
    "# X_std_cleaned_train, X_std_cleaned_test, Y_std_cleaned_train, Y_std_cleaned_test = train_test_split(std_cleaned_X, std_cleaned_Y, test_size = 0.30, random_state = 1)\n",
    "for n in [5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]:\n",
    "    model_knn = KNeighborsRegressor(n_neighbors=n, p=2, weights=\"distance\")\n",
    "    model_knn.fit(X_std_cleaned_train, Y_std_cleaned_train)\n",
    "    print(\"\\n Std + Outlier removed n_neighbors: usual p = 2\", n)\n",
    "    print(\"Train:: \",  model_knn.score(X_std_cleaned_train,Y_std_cleaned_train))\n",
    "    print(\"Test:: \", model_knn.score(X_std_cleaned_test, Y_std_cleaned_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f3f1b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "std_df = df\n",
    "\n",
    "std_df[\"cement\"] = min_max_scale.fit_transform(std_df[[\"cement\"]])\n",
    "\n",
    "std_df[\"slag\"] = min_max_scale.fit_transform(std_df[[\"slag\"]])\n",
    "\n",
    "std_df[\"water\"] = min_max_scale.fit_transform(std_df[[\"water\"]])\n",
    "\n",
    "std_df[\"ash\"] = min_max_scale.fit_transform(std_df[[\"ash\"]])\n",
    "\n",
    "std_df[\"superplastic\"] = min_max_scale.fit_transform(std_df[[\"superplastic\"]])\n",
    "\n",
    "std_df[\"coarseagg\"] = min_max_scale.fit_transform(std_df[[\"coarseagg\"]])\n",
    "std_df[\"fineagg\"] = min_max_scale.fit_transform(std_df[[\"fineagg\"]])\n",
    "std_df[\"age\"] = min_max_scale.fit_transform(std_df[[\"age\"]])\n",
    "\n",
    "std_Y = std_df[[\"strength\"]]\n",
    "std_X = std_df.drop([\"strength\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "83f879de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Standarised + n_neighbors: usual p = 1 5\n",
      "Train::  0.8325396649549555\n",
      "Test::  0.7588758784232201\n",
      "\n",
      " Standarised + n_neighbors: usual p = 1 6\n",
      "Train::  0.8202687071154866\n",
      "Test::  0.7472197804340697\n",
      "\n",
      " Standarised + n_neighbors: usual p = 1 7\n",
      "Train::  0.8074705138968455\n",
      "Test::  0.7418474956890868\n",
      "\n",
      " Standarised + n_neighbors: usual p = 1 8\n",
      "Train::  0.8025872720639196\n",
      "Test::  0.7433254679320429\n",
      "\n",
      " Standarised + n_neighbors: usual p = 1 9\n",
      "Train::  0.7981175595626173\n",
      "Test::  0.7285744633683233\n",
      "\n",
      " Standarised + n_neighbors: usual p = 1 10\n",
      "Train::  0.7892172834986473\n",
      "Test::  0.7197742483073805\n",
      "\n",
      " Standarised + n_neighbors: usual p = 1 11\n",
      "Train::  0.7828889256143912\n",
      "Test::  0.7188062886671343\n",
      "\n",
      " Standarised + n_neighbors: usual p = 1 12\n",
      "Train::  0.7733452384744721\n",
      "Test::  0.7171657450599991\n",
      "\n",
      " Standarised + n_neighbors: usual p = 1 13\n",
      "Train::  0.7634596887908844\n",
      "Test::  0.710962923115712\n",
      "\n",
      " Standarised + n_neighbors: usual p = 1 14\n",
      "Train::  0.7542203675298917\n",
      "Test::  0.7037829582513133\n",
      "\n",
      " Standarised + n_neighbors: usual p = 1 15\n",
      "Train::  0.7489045252926758\n",
      "Test::  0.7014123474791246\n",
      "\n",
      " Standarised + n_neighbors: usual p = 1 16\n",
      "Train::  0.7428305808167153\n",
      "Test::  0.6948792635910322\n",
      "\n",
      " Standarised + n_neighbors: usual p = 1 17\n",
      "Train::  0.7403866694157666\n",
      "Test::  0.6880110715386785\n",
      "\n",
      " Standarised + n_neighbors: usual p = 1 18\n",
      "Train::  0.732260814306574\n",
      "Test::  0.680684670040703\n",
      "\n",
      " Standarised + n_neighbors: usual p = 1 19\n",
      "Train::  0.7261289583576134\n",
      "Test::  0.6758051688367993\n",
      "\n",
      " Standarised + n_neighbors: usual p = 1 20\n",
      "Train::  0.7225411855660615\n",
      "Test::  0.6681138741211223\n"
     ]
    }
   ],
   "source": [
    "X_std_train, X_std_test, Y_std_train, Y_std_test = train_test_split(std_X, std_Y, test_size = 0.30, random_state = 1)\n",
    "for n in [5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]:\n",
    "    model_knn = KNeighborsRegressor(n_neighbors=n, p=1)\n",
    "    model_knn.fit(X_std_train, Y_std_train)\n",
    "    print(\"\\n Standarised + n_neighbors: usual p = 1\", n)\n",
    "    print(\"Train:: \",  model_knn.score(X_std_train,Y_std_train))\n",
    "    print(\"Test:: \", model_knn.score(X_std_test, Y_std_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "014b78e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_Y = cleaned_df[[\"strength\"]]\n",
    "cleaned_X = cleaned_df.drop([\"strength\"], axis = 1)\n",
    "X_cleaned_train, X_cleaned_test, Y_cleaned_train, Y_cleaned_test = train_test_split(cleaned_X, cleaned_Y, test_size = 0.30, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d5ce843d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df[[\"strength\"]]\n",
    "X = df.drop([\"strength\"], axis = 1)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.30, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "250f628a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear:: \n",
      "Test:: 0.7320709753755357\n",
      "Train:: 0.7254766837389761\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "model_lr = LinearRegression()\n",
    "model_lr.fit(X_train, Y_train)\n",
    "# Fit the model with the train data\n",
    "print(\"Linear:: \")\n",
    "print(\"Test::\", model_lr.score(X_test, Y_test))\n",
    "print(\"Train::\", model_lr.score(X_train, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e6abb3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial\n",
      "Train:  0.8016388489476829\n",
      "Test:  0.7715736962399415\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn import linear_model\n",
    "\n",
    "# Degree can be varied to play around and check when model is over fitting\n",
    "# poly = PolynomialFeatures(degree = 1, interaction_only = True)\n",
    "poly = PolynomialFeatures(degree = 2, interaction_only = True)\n",
    "# poly = PolynomialFeatures(degree = 3, interaction_only = True)\n",
    "# poly = PolynomialFeatures(degree = 4, interaction_only = True)\n",
    "\n",
    "X_train2 = poly.fit_transform(X_train)\n",
    "X_test2 = poly.fit_transform(X_test)\n",
    "\n",
    "poly_clf = linear_model.LinearRegression()\n",
    "\n",
    "poly_clf.fit(X_train2, Y_train)\n",
    "\n",
    "y_pred = poly_clf.predict(X_test2)\n",
    "\n",
    "print(\"Polynomial\")\n",
    "print(\"Train: \", poly_clf.score(X_train2, Y_train))\n",
    "print(\"Test: \", poly_clf.score(X_test2, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "302a1564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial + removed outliers\n",
      "Train:  0.8016388489476829\n",
      "Test:  0.7715736962399415\n"
     ]
    }
   ],
   "source": [
    "# e varied to play around and check when model is over fitting\n",
    "# poly = PolynomialFeatures(degree = 1, interaction_only = True)\n",
    "poly = PolynomialFeatures(degree = 2, interaction_only = True)\n",
    "# poly = PolynomialFeatures(degree = 3, interaction_only = True)\n",
    "# poly = PolynomialFeatures(degree = 4, interaction_only = True)\n",
    "\n",
    "X_train2 = poly.fit_transform(X_cleaned_train)\n",
    "X_test2 = poly.fit_transform(X_cleaned_test)\n",
    "\n",
    "poly_clf = linear_model.LinearRegression()\n",
    "\n",
    "poly_clf.fit(X_train2, Y_cleaned_train)\n",
    "\n",
    "y_pred = poly_clf.predict(X_test2)\n",
    "\n",
    "print(\"Polynomial + removed outliers\")\n",
    "print(\"Train: \", poly_clf.score(X_train2, Y_train))\n",
    "print(\"Test: \", poly_clf.score(X_test2, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0562cc39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear:: Cleaned data(removeoutlier) \n",
      "Test:: 0.7320709753755357\n",
      "Train:: 0.7254766837389761\n"
     ]
    }
   ],
   "source": [
    "model_lr = LinearRegression()\n",
    "model_lr.fit(X_cleaned_train, Y_cleaned_train)\n",
    "# Fit the model with the train data\n",
    "print(\"Linear:: Cleaned data(removeoutlier) \")\n",
    "print(\"Test::\", model_lr.score(X_cleaned_test, Y_cleaned_test))\n",
    "print(\"Train::\", model_lr.score(X_cleaned_train, Y_cleaned_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ebe0b8a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cement          float64\n",
       "slag            float64\n",
       "ash             float64\n",
       "water           float64\n",
       "superplastic    float64\n",
       "coarseagg       float64\n",
       "fineagg         float64\n",
       "age             float64\n",
       "strength        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2ed83184",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "min_max_scale = MinMaxScaler()\n",
    "\n",
    "\n",
    "std_cleaned_df = cleaned_df\n",
    "\n",
    "std_cleaned_df[\"cement\"] = min_max_scale.fit_transform(std_cleaned_df[[\"cement\"]])\n",
    "\n",
    "std_cleaned_df[\"slag\"] = min_max_scale.fit_transform(std_cleaned_df[[\"slag\"]])\n",
    "\n",
    "std_cleaned_df[\"water\"] = min_max_scale.fit_transform(std_cleaned_df[[\"water\"]])\n",
    "\n",
    "std_cleaned_df[\"ash\"] = min_max_scale.fit_transform(std_cleaned_df[[\"ash\"]])\n",
    "\n",
    "std_cleaned_df[\"superplastic\"] = min_max_scale.fit_transform(std_cleaned_df[[\"superplastic\"]])\n",
    "\n",
    "std_cleaned_df[\"coarseagg\"] = min_max_scale.fit_transform(std_cleaned_df[[\"coarseagg\"]])\n",
    "std_cleaned_df[\"fineagg\"] = min_max_scale.fit_transform(std_cleaned_df[[\"fineagg\"]])\n",
    "std_cleaned_df[\"age\"] = min_max_scale.fit_transform(std_cleaned_df[[\"age\"]])\n",
    "\n",
    "\n",
    "Y = std_cleaned_df[[\"strength\"]]\n",
    "X = std_cleaned_df.drop([\"strength\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0843df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "min_max_scale = MinMaxScaler()\n",
    "\n",
    "\n",
    "min_max_cleaned_df = cleaned_df\n",
    "\n",
    "min_max_cleaned_df[\"cement\"] = min_max_scale.fit_transform(min_max_cleaned_df[[\"cement\"]])\n",
    "\n",
    "min_max_cleaned_df[\"slag\"] = min_max_scale.fit_transform(min_max_cleaned_df[[\"slag\"]])\n",
    "\n",
    "min_max_cleaned_df[\"water\"] = min_max_scale.fit_transform(min_max_cleaned_df[[\"water\"]])\n",
    "\n",
    "min_max_cleaned_df[\"ash\"] = min_max_scale.fit_transform(min_max_cleaned_df[[\"ash\"]])\n",
    "\n",
    "min_max_cleaned_df[\"superplastic\"] = min_max_scale.fit_transform(min_max_cleaned_df[[\"superplastic\"]])\n",
    "\n",
    "min_max_cleaned_df[\"coarseagg\"] = min_max_scale.fit_transform(min_max_cleaned_df[[\"coarseagg\"]])\n",
    "min_max_cleaned_df[\"fineagg\"] = min_max_scale.fit_transform(min_max_cleaned_df[[\"fineagg\"]])\n",
    "min_max_cleaned_df[\"age\"] = min_max_scale.fit_transform(min_max_cleaned_df[[\"age\"]])\n",
    "\n",
    "\n",
    "Y = min_max_cleaned_df[[\"strength\"]]\n",
    "X = min_max_cleaned_df.drop([\"strength\"], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "00faa15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear + removed outliers + Normalization\n",
      "Test:: 0.7320709753755357\n",
      "Train:: 0.7254766837389761\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.30, random_state = 1)\n",
    "\n",
    "# Instantiate the model\n",
    "model_lr = LinearRegression()\n",
    "model_lr.fit(X_train, Y_train)\n",
    "# Fit the model with the train data\n",
    "print(\"Linear + removed outliers + Normalization\")\n",
    "print(\"Test::\", model_lr.score(X_test, Y_test))\n",
    "print(\"Train::\", model_lr.score(X_train, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e0561abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial + removed outliers + Normalization\n",
      "Train:  0.8016388489476829\n",
      "Test:  0.7715736962399415\n"
     ]
    }
   ],
   "source": [
    "poly = PolynomialFeatures(degree = 2, interaction_only = True)\n",
    "# poly = PolynomialFeatures(degree = 3, interaction_only = True)\n",
    "# poly = PolynomialFeatures(degree = 4, interaction_only = True)\n",
    "\n",
    "X_train2 = poly.fit_transform(X_train)\n",
    "X_test2 = poly.fit_transform(X_test)\n",
    "\n",
    "poly_clf = linear_model.LinearRegression()\n",
    "\n",
    "poly_clf.fit(X_train2, Y_train)\n",
    "\n",
    "y_pred = poly_clf.predict(X_test2)\n",
    "\n",
    "print(\"Polynomial + removed outliers + Normalization\")\n",
    "print(\"Train: \", poly_clf.score(X_train2, Y_train))\n",
    "print(\"Test: \", poly_clf.score(X_test2, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9ca6575f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Kernel:  linear\n",
      "train:  0.6698538127524506\n",
      "test:  0.6855004765312129\n",
      "\n",
      " Kernel:  poly\n",
      "train:  0.8529158603993915\n",
      "test:  0.8243709276438238\n",
      "\n",
      " Kernel:  rbf\n",
      "train:  0.7306301210396156\n",
      "test:  0.7234106583659335\n",
      "\n",
      " Kernel:  sigmoid\n",
      "train:  0.28664398738219343\n",
      "test:  0.2675985638036016\n",
      "\n",
      "gamma='auto')  Kernel:  linear\n",
      "train:  0.6698538127524506\n",
      "test:  0.6855004765312129\n",
      "\n",
      "gamma='auto')  Kernel:  poly\n",
      "train:  0.02530403129331882\n",
      "test:  0.022501165661437006\n",
      "\n",
      "gamma='auto')  Kernel:  rbf\n",
      "train:  0.41966849737246925\n",
      "test:  0.41980028215718235\n",
      "\n",
      "gamma='auto')  Kernel:  sigmoid\n",
      "train:  0.28595292730553934\n",
      "test:  0.283931581703427\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "\n",
    "# kernel : {'linear', 'poly', 'rbf', 'sigmoid', 'precomputed'} or callable,          default='rbf'\n",
    "#      Specifies the kernel type to be used in the algorithm.\n",
    "#      If none is given, 'rbf' will be used. If a callable is given it is\n",
    "#      used to precompute the kernel matrix.\n",
    "\n",
    "# degree : int, default=3\n",
    "#     Degree of the polynomial kernel function ('poly').\n",
    "#     Must be non-negative. Ignored by all other kernels.\n",
    "\n",
    "# gamma : {'scale', 'auto'} or float, default='scale'\n",
    "#     Kernel coefficient for 'rbf', 'poly' and 'sigmoid'.\n",
    "\n",
    "#     - if ``gamma='scale'`` (default) is passed then it uses\n",
    "#       1 / (n_features * X.var()) as value of gamma,\n",
    "#     - if 'auto', uses 1 / n_features\n",
    "#     - if float, must be non-negative.\n",
    "\n",
    "#     .. versionchanged:: 0.22\n",
    "#        The default value of ``gamma`` changed from 'auto' to 'scale'.\n",
    "\n",
    "# coef0 : float, default=0.0\n",
    "#     Independent term in kernel function.\n",
    "#     It is only significant in 'poly' and 'sigmoid'.\n",
    "\n",
    "# tol : float, default=1e-3\n",
    "#     Tolerance for stopping criterion.\n",
    "\n",
    "# C : float, default=1.0\n",
    "#     Regularization parameter. The strength of the regularization is\n",
    "#     inversely proportional to C. Must be strictly positive.\n",
    "#     The penalty is a squared l2 penalty.\n",
    "\n",
    "# epsilon : float, default=0.1\n",
    "#      Epsilon in the epsilon-SVR model. It specifies the epsilon-tube\n",
    "#      within which no penalty is associated in the training loss function\n",
    "#      with points predicted within a distance epsilon from the actual\n",
    "#      value. Must be non-negative.\n",
    "\n",
    "# shrinking : bool, default=True\n",
    "#     Whether to use the shrinking heuristic.\n",
    "#     See the :ref:`User Guide <shrinking_svm>`.\n",
    "\n",
    "# cache_size : float, default=200\n",
    "#     Specify the size of the kernel cache (in MB).\n",
    "\n",
    "# verbose : bool, default=False\n",
    "#     Enable verbose output. Note that this setting takes advantage of a\n",
    "#     per-process runtime setting in libsvm that, if enabled, may not work\n",
    "#     properly in a multithreaded context.\n",
    "\n",
    "# max_iter : int, default=-1\n",
    "#     Hard limit on iterations within solver, or -1 for no limit.\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "Y = min_max_cleaned_df[[\"strength\"]]\n",
    "X = min_max_cleaned_df.drop([\"strength\"], axis = 1)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.30, random_state = 1)\n",
    "\n",
    "\n",
    "kernel : {'linear', 'poly', 'rbf', 'sigmoid', 'precomputed'} \n",
    "model_svr = SVR()\n",
    "\n",
    "\n",
    "for kernel in ['linear', 'poly', 'rbf', 'sigmoid']:\n",
    "    model_svr = SVR(kernel=kernel)\n",
    "    model_svr.fit(X_std_train, Y_std_train)\n",
    "    print(\"\\n Kernel: \", kernel)\n",
    "    print(\"train: \",model_svr.score(X_std_train, Y_std_train))\n",
    "    print(\"test: \", model_svr.score(X_std_test, Y_std_test))\n",
    "    \n",
    "for kernel in ['linear', 'poly', 'rbf', 'sigmoid']:\n",
    "    model_svr = SVR(kernel=kernel, gamma='auto')\n",
    "    model_svr.fit(X_std_train, Y_std_train)\n",
    "    print(\"\\ngamma='auto')  Kernel: \", kernel)\n",
    "    print(\"train: \",model_svr.score(X_std_train, Y_std_train))\n",
    "    print(\"test: \", model_svr.score(X_std_test, Y_std_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1c6e95ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Kernel:  linear\n",
      "train:  0.6698538127524506\n",
      "test:  0.6855004765312129\n",
      "\n",
      " Kernel:  poly\n",
      "train:  0.8529158603993915\n",
      "test:  0.8243709276438238\n",
      "\n",
      " Kernel:  rbf\n",
      "train:  0.7306301210396156\n",
      "test:  0.7234106583659335\n",
      "\n",
      " Kernel:  sigmoid\n",
      "train:  0.28664398738219343\n",
      "test:  0.2675985638036016\n",
      "\n",
      "gamma='auto')  Kernel:  linear\n",
      "train:  0.6698538127524506\n",
      "test:  0.6855004765312129\n",
      "\n",
      "gamma='auto')  Kernel:  poly\n",
      "train:  0.02530403129331882\n",
      "test:  0.022501165661437006\n",
      "\n",
      "gamma='auto')  Kernel:  rbf\n",
      "train:  0.41966849737246925\n",
      "test:  0.41980028215718235\n",
      "\n",
      "gamma='auto')  Kernel:  sigmoid\n",
      "train:  0.28595292730553934\n",
      "test:  0.283931581703427\n"
     ]
    }
   ],
   "source": [
    "Y = std_cleaned_df[[\"strength\"]]\n",
    "X = std_cleaned_df.drop([\"strength\"], axis = 1)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.30, random_state = 1)\n",
    "\n",
    "\n",
    "kernel : {'linear', 'poly', 'rbf', 'sigmoid', 'precomputed'} \n",
    "model_svr = SVR()\n",
    "\n",
    "\n",
    "for kernel in ['linear', 'poly', 'rbf', 'sigmoid']:\n",
    "    model_svr = SVR(kernel=kernel)\n",
    "    model_svr.fit(X_std_train, Y_std_train)\n",
    "    print(\"\\n Kernel: \", kernel)\n",
    "    print(\"train: \",model_svr.score(X_std_train, Y_std_train))\n",
    "    print(\"test: \", model_svr.score(X_std_test, Y_std_test))\n",
    "    \n",
    "for kernel in ['linear', 'poly', 'rbf', 'sigmoid']:\n",
    "    model_svr = SVR(kernel=kernel, gamma='auto')\n",
    "    model_svr.fit(X_std_train, Y_std_train)\n",
    "    print(\"\\ngamma='auto')  Kernel: \", kernel)\n",
    "    print(\"train: \",model_svr.score(X_std_train, Y_std_train))\n",
    "    print(\"test: \", model_svr.score(X_std_test, Y_std_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e075f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# std_cleaned_df, min_max_cleaned_df\n",
    "\n",
    "\n",
    "# cleaned_df, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "438f2163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "65/65 [==============================] - 1s 5ms/step - loss: 1608.8234 - accuracy: 0.0000e+00 - val_loss: 1519.8251 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1352.1606 - accuracy: 0.0000e+00 - val_loss: 837.4237 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 375.5485 - accuracy: 0.0000e+00 - val_loss: 273.1707 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 222.1454 - accuracy: 0.0000e+00 - val_loss: 250.7216 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 209.4583 - accuracy: 0.0000e+00 - val_loss: 235.0767 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 197.3427 - accuracy: 0.0000e+00 - val_loss: 218.5287 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 183.7449 - accuracy: 0.0000e+00 - val_loss: 202.4561 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 171.4515 - accuracy: 0.0000e+00 - val_loss: 188.3281 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 158.7379 - accuracy: 0.0000e+00 - val_loss: 169.9345 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 147.3579 - accuracy: 0.0000e+00 - val_loss: 154.3583 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13ffc0d10>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "Y=cleaned_df[\"strength\"]\n",
    "X=cleaned_df.drop(columns=[\"strength\"], axis=1)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.30)\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Dense(units=6,activation=\"relu\",input_dim=8,kernel_initializer='uniform'))\n",
    "model.add(Dense(units=20,kernel_initializer='uniform',activation=\"relu\"))\n",
    "model.add(Dense(units=20,kernel_initializer='uniform',activation=\"relu\"))\n",
    "model.add(Dense(units=20,kernel_initializer='uniform',activation=\"relu\"))\n",
    "model.add(Dense(units=1))\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"mean_squared_error\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=10, epochs=10, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9dba43de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "65/65 [==============================] - 2s 5ms/step - loss: 1567.3054 - accuracy: 0.0000e+00 - val_loss: 1417.0126 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 1059.1633 - accuracy: 0.0000e+00 - val_loss: 333.9990 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 253.9579 - accuracy: 0.0000e+00 - val_loss: 232.8631 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 219.3105 - accuracy: 0.0000e+00 - val_loss: 216.4079 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 200.5018 - accuracy: 0.0000e+00 - val_loss: 202.8103 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 182.5514 - accuracy: 0.0000e+00 - val_loss: 190.0970 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 165.8078 - accuracy: 0.0000e+00 - val_loss: 168.8199 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 148.7345 - accuracy: 0.0000e+00 - val_loss: 157.4466 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 133.4425 - accuracy: 0.0000e+00 - val_loss: 142.1510 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "65/65 [==============================] - 0s 2ms/step - loss: 118.6971 - accuracy: 0.0000e+00 - val_loss: 126.2705 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1419ca050>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "Y=std_df[\"strength\"]\n",
    "X=std_df.drop(columns=[\"strength\"], axis=1)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.30)\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Dense(units=6,activation=\"relu\",input_dim=8,kernel_initializer='uniform'))\n",
    "model.add(Dense(units=20,kernel_initializer='uniform',activation=\"relu\"))\n",
    "model.add(Dense(units=20,kernel_initializer='uniform',activation=\"relu\"))\n",
    "model.add(Dense(units=20,kernel_initializer='uniform',activation=\"relu\"))\n",
    "model.add(Dense(units=1))\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"mean_squared_error\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=10, epochs=10, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "af183181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "6/6 [==============================] - 2s 50ms/step - loss: 1550.1656 - accuracy: 0.0000e+00 - val_loss: 1554.0814 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1549.1162 - accuracy: 0.0000e+00 - val_loss: 1552.9429 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1547.9421 - accuracy: 0.0000e+00 - val_loss: 1551.6838 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1546.6333 - accuracy: 0.0000e+00 - val_loss: 1550.2710 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1545.1582 - accuracy: 0.0000e+00 - val_loss: 1548.6580 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1543.4614 - accuracy: 0.0000e+00 - val_loss: 1546.7908 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1541.4865 - accuracy: 0.0000e+00 - val_loss: 1544.5972 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1539.1437 - accuracy: 0.0000e+00 - val_loss: 1541.9711 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1536.3081 - accuracy: 0.0000e+00 - val_loss: 1538.7650 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/30\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1532.7979 - accuracy: 0.0000e+00 - val_loss: 1534.7682 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1528.4495 - accuracy: 0.0000e+00 - val_loss: 1529.6802 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1522.8651 - accuracy: 0.0000e+00 - val_loss: 1523.1053 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/30\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1515.5601 - accuracy: 0.0000e+00 - val_loss: 1514.4883 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/30\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1506.0726 - accuracy: 0.0000e+00 - val_loss: 1503.0669 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1493.1847 - accuracy: 0.0000e+00 - val_loss: 1487.9010 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1475.9429 - accuracy: 0.0000e+00 - val_loss: 1467.7944 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/30\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1453.6476 - accuracy: 0.0000e+00 - val_loss: 1441.1281 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/30\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1423.9517 - accuracy: 0.0000e+00 - val_loss: 1406.1754 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/30\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1385.3873 - accuracy: 0.0000e+00 - val_loss: 1360.7852 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/30\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1335.4172 - accuracy: 0.0000e+00 - val_loss: 1302.8925 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/30\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1271.9803 - accuracy: 0.0000e+00 - val_loss: 1230.4413 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/30\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1193.6743 - accuracy: 0.0000e+00 - val_loss: 1141.5557 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/30\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1098.0619 - accuracy: 0.0000e+00 - val_loss: 1035.0846 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/30\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 984.6140 - accuracy: 0.0000e+00 - val_loss: 911.2622 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/30\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 857.6507 - accuracy: 0.0000e+00 - val_loss: 772.6519 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/30\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 715.5938 - accuracy: 0.0000e+00 - val_loss: 627.7812 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/30\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 571.0324 - accuracy: 0.0000e+00 - val_loss: 487.7702 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/30\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 440.4266 - accuracy: 0.0000e+00 - val_loss: 367.0640 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 333.8246 - accuracy: 0.0000e+00 - val_loss: 282.4692 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 270.5229 - accuracy: 0.0000e+00 - val_loss: 241.0813 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x148a07050>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# std_cleaned_df, min_max_cleaned_df\n",
    "Y=std_cleaned_df[\"strength\"]\n",
    "X=std_cleaned_df.drop(columns=[\"strength\"], axis=1)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.3, random_state=1)\n",
    "\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Dense(units=6,kernel_initializer='uniform',activation=\"relu\",input_dim=8))\n",
    "model.add(Dense(units=20,kernel_initializer='uniform',activation=\"relu\"))\n",
    "model.add(Dense(units=20,kernel_initializer='uniform',activation=\"relu\"))\n",
    "model.add(Dense(units=20,kernel_initializer='uniform',activation=\"relu\"))\n",
    "model.add(Dense(units=1))\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"mean_squared_error\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=100, epochs=30, validation_split=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "183b39aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.09768937191782123"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "Y_pred = model.predict(X_train)\n",
    "r2_score(Y_train, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "946d2546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.12099636988812912"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "Y_pred = model.predict(X_test)\n",
    "r2_score(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6cc78907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "44/44 [==============================] - 1s 6ms/step - loss: 1596.2422 - val_loss: 1341.8503\n",
      "Epoch 2/10\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1524.9545 - val_loss: 1145.1066\n",
      "Epoch 3/10\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 814.1451 - val_loss: 233.6623\n",
      "Epoch 4/10\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 238.5326 - val_loss: 209.4787\n",
      "Epoch 5/10\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 216.7601 - val_loss: 191.1438\n",
      "Epoch 6/10\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 203.9935 - val_loss: 186.3866\n",
      "Epoch 7/10\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 187.4305 - val_loss: 169.0038\n",
      "Epoch 8/10\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 173.8543 - val_loss: 163.4581\n",
      "Epoch 9/10\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 159.9068 - val_loss: 156.7834\n",
      "Epoch 10/10\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 146.2967 - val_loss: 134.2346\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x147e23390>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y=min_max_cleaned_df[\"strength\"]\n",
    "X=min_max_cleaned_df.drop(columns=[\"strength\"], axis=1)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.30)\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Dense(units=6,activation=\"relu\",input_dim=8,kernel_initializer='uniform'))\n",
    "model.add(Dense(units=20,kernel_initializer='uniform',activation=\"relu\"))\n",
    "model.add(Dense(units=20,kernel_initializer='uniform',activation=\"relu\"))\n",
    "model.add(Dense(units=20,kernel_initializer='uniform',activation=\"relu\"))\n",
    "model.add(Dense(units=20,kernel_initializer='uniform',activation=\"relu\"))\n",
    "model.add(Dense(units=1))\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=15, epochs=10, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1bcbf0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.47719593570569063"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "Y_pred = model.predict(X_test)\n",
    "r2_score(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "21bc8dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.48768416135090675"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "Y_pred = model.predict(X_train)\n",
    "r2_score(Y_train, Y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
